{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superposition Explorer Tutorial\n",
    "\n",
    "Investigate polysemanticity and feature superposition in transformer representations.\n",
    "\n",
    "## What is Superposition?\n",
    "\n",
    "Neural networks often represent more features than they have dimensions. This is called **superposition** - features are encoded in overlapping, non-orthogonal directions.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Polysemanticity**: A single neuron responds to multiple unrelated concepts\n",
    "- **Superposition**: More features than dimensions through interference\n",
    "- **Feature interference**: When features aren't perfectly orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from superposition_explorer import SuperpositionAnalyzer, FeatureProbe\n",
    "\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Synthetic Data\n",
    "\n",
    "We'll create activations with known superposition properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic activations with superposition\n",
    "n_samples = 1000\n",
    "n_dims = 256\n",
    "n_true_features = 512  # More features than dimensions!\n",
    "\n",
    "# Random feature directions (some overlap due to superposition)\n",
    "feature_directions = np.random.randn(n_true_features, n_dims)\n",
    "feature_directions /= np.linalg.norm(feature_directions, axis=1, keepdims=True)\n",
    "\n",
    "# Sparse feature activations\n",
    "feature_activations = np.random.exponential(1, (n_samples, n_true_features))\n",
    "feature_activations *= (np.random.rand(n_samples, n_true_features) > 0.9)  # 90% sparse\n",
    "\n",
    "# Reconstruct activations through superposition\n",
    "activations = feature_activations @ feature_directions\n",
    "\n",
    "print(f\"Created {n_samples} samples with {n_dims} dimensions\")\n",
    "print(f\"Encoding {n_true_features} features (superposition ratio: {n_true_features/n_dims:.1f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Superposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = SuperpositionAnalyzer(n_features=n_dims)\n",
    "\n",
    "# Compute metrics\n",
    "metrics = analyzer.compute_metrics(activations)\n",
    "\n",
    "print(\"Superposition Metrics:\")\n",
    "print(f\"  Effective dimensionality: {metrics.effective_dimensionality:.2f}\")\n",
    "print(f\"  Sparsity: {metrics.sparsity:.4f}\")\n",
    "print(f\"  Feature interference: {metrics.interference:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "activations_2d = pca.fit_transform(activations[:500])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(activations_2d[:, 0], activations_2d[:, 1], alpha=0.5, s=10)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Activation Space (PCA)')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Variance explained: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Find Polysemantic Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create concept labels\n",
    "concept_labels = np.random.randint(0, 10, n_samples)\n",
    "\n",
    "# Find polysemantic neurons\n",
    "polysemantic = analyzer.find_polysemantic_neurons(\n",
    "    activations,\n",
    "    concept_labels,\n",
    "    threshold=0.3,\n",
    ")\n",
    "\n",
    "print(f\"Found {len(polysemantic)} polysemantic neurons out of {n_dims}\")\n",
    "print(f\"Polysemanticity rate: {len(polysemantic)/n_dims:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interference Matrix\n",
    "\n",
    "Visualize how features interfere with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute interference (correlation) matrix\n",
    "interference = np.corrcoef(activations.T)[:50, :50]  # First 50 dims\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(interference, cmap='RdBu', vmin=-1, vmax=1)\n",
    "plt.colorbar(label='Correlation')\n",
    "plt.title('Feature Interference Matrix')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Feature Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This tutorial demonstrated:\n",
    "1. How superposition allows encoding more features than dimensions\n",
    "2. Metrics to quantify superposition (effective dimensionality, sparsity)\n",
    "3. Visualization of feature spaces and interference\n",
    "4. Detection of polysemantic neurons\n",
    "\n",
    "For more, see the Anthropic papers on superposition and polysemanticity!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
